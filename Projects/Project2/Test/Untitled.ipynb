{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator, FormatStrFormatter\n",
    "import numpy as np\n",
    "from random import random, seed\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import statistics\n",
    "from time import time\n",
    "from scipy.stats import norm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "scaler=StandardScaler()\n",
    "type(scaler)\n",
    "\n",
    "\n",
    "\n",
    "def FrankeFunction(x,y): #code from task\n",
    "\tterm1 = 0.75*np.exp(-(0.25*(9*x-2)**2) - 0.25*((9*y-2)**2))\n",
    "\tterm2 = 0.75*np.exp(-((9*x+1)**2)/49.0 - 0.1*(9*y+1))\n",
    "\tterm3 = 0.5*np.exp(-(9*x-7)**2/4.0 - 0.25*((9*y-3)**2))\n",
    "\tterm4 = -0.2*np.exp(-(9*x-4)**2 - (9*y-7)**2)\n",
    "\treturn term1 + term2 + term3 + term4\n",
    "\n",
    "#calculates R2 score and MSE\n",
    "def R2(y_data, y_model): #week 35 exercise\n",
    "    return 1 - np.sum((y_data - y_model) ** 2) / np.sum((y_data - np.mean(y_data)) ** 2)\n",
    "def MSE(y_data,y_model):\n",
    "    n = np.size(y_model)\n",
    "    return np.sum((y_data-y_model)**2)/n\n",
    "\n",
    "\n",
    "def SVD(A): #week35 SVD\n",
    "    U, S, VT = np.linalg.svd(A,full_matrices=True)\n",
    "    D = np.zeros((len(U),len(VT)))\n",
    "    print(\"shape D= \", np.shape(D))\n",
    "    print(\"Shape S= \",np.shape(S))\n",
    "    print(\"lenVT =\",len(VT))\n",
    "    print(\"lenU =\",len(U))\n",
    "    D = np.eye(len(U),len(VT))*S\n",
    "    \"\"\"\n",
    "    for i in range(0,VT.shape[0]): #was len(VT)\n",
    "        D[i,i]=S[i]\n",
    "        print(\"i=\",i)\"\"\"\n",
    "    return U @ D @ VT\n",
    "\n",
    "#Makes a 3d plot of the franke function\n",
    "def Plot_franke_function(): #code from task\n",
    "\tfig = plt.figure()\n",
    "\tax = fig.gca(projection=\"3d\")\n",
    "\n",
    "\t# Make data.\n",
    "\tx = np.arange(0, 1, 0.05)\n",
    "\ty = np.arange(0, 1, 0.05)\n",
    "\tx, y = np.meshgrid(x,y)\n",
    "\tz = FrankeFunction(x, y)\n",
    "\n",
    "\t# Plot the surface.\n",
    "\tsurf = ax.plot_surface(x, y, z, cmap=cm.coolwarm,\n",
    "\tlinewidth=0, antialiased=False)\n",
    "\n",
    "\t# Customize the z axis.\n",
    "\tax.set_zlim(-0.10, 1.40)\n",
    "\tax.zaxis.set_major_locator(LinearLocator(10))\n",
    "\tax.zaxis.set_major_formatter(FormatStrFormatter('%.02f'))\n",
    "\n",
    "\t# Add a color bar which maps values to colors.\n",
    "\tfig.colorbar(surf, shrink=0.5, aspect=5)\n",
    "\tplt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Setting up design matrix from week 35-36 lecture slides\n",
    "def create_X(x, y, n):\n",
    "\tif len(x.shape) > 1:\n",
    "\t\tx = np.ravel(x)\n",
    "\t\ty = np.ravel(y)\n",
    "\n",
    "\tN = len(x)\n",
    "\tl = int((n+1)*(n+2)/2)\t\t# Number of elements in beta\n",
    "\tX = np.ones((N,l))\n",
    "\n",
    "\tfor i in range(1,n+1):\n",
    "\t\tq = int((i)*(i+1)/2)\n",
    "\t\tfor k in range(i+1):\n",
    "\t\t\tX[:,q+k] = (x**(i-k))*(y**k)\n",
    "\n",
    "\treturn X\n",
    "\n",
    "\n",
    "\n",
    "def OLS_solver(designmatrix, datapoints):\n",
    "\tX = designmatrix\n",
    "\tz = datapoints\n",
    "\n",
    "\n",
    "\t#Splitting training and test data (20%test)\n",
    "\tX_train, X_test, z_train, z_test = train_test_split(X, z, test_size=0.2)\n",
    "\n",
    "\t#scaling the the input with standardscalar (week35)\n",
    "\tscaler = StandardScaler()\n",
    "\tscaler.fit(X_train)\n",
    "\n",
    "\tX_scaled = scaler.transform(X_train)\n",
    "\n",
    "\t#used to scale train and test\n",
    "\tz_mean = np.mean(z_train)\n",
    "\tz_sigma = np.std(z_train)\n",
    "\n",
    "\tz_train = (z_train- z_mean)/z_sigma\n",
    "\n",
    "\n",
    "\t#Singular value decomposition (removed as it doesn't work ref group teacher)\n",
    "\t#X_train = SVD(X_train) \n",
    "\n",
    "\n",
    "\t# Calculating Beta Ordinary Least Square with matrix inversion\n",
    "\tols_beta = np.linalg.pinv(X_train.T @ X_train) @ X_train.T @ z_train #psudoinverse\n",
    "\n",
    "\t#Scaling test data\n",
    "\tz_test = (z_test- z_mean)/z_sigma\n",
    "\n",
    "\tX_test = scaler.transform(X_test)\n",
    "\n",
    "\tztilde = X_train @ ols_beta\n",
    "\t#print(\"Training R2\")\n",
    "\t#print(R2(z_train,ztilde))\n",
    "\t#print(\"Training MSE\")\n",
    "\t#print(MSE(z_train,ztilde))\n",
    "\n",
    "\n",
    "\tzpredict = X_test @ ols_beta\n",
    "\t#print(\"Test R2\")\n",
    "\t#print(R2(z_test,zpredict))\n",
    "\t#print(\"Test MSE\")\n",
    "\t#print(MSE(z_test,zpredict))\n",
    "    \n",
    "\tprint(z_sigma**2 * np.linalg.pinv(X_train.T @ X_train)) #Agree correct? beta_ols_variance = \n",
    "\treturn ols_beta, MSE(z_train,ztilde), MSE(z_test,zpredict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------Task 2------\n",
    "\n",
    "#setting up data\n",
    "n = 500 #does it matter?\n",
    "\n",
    "x = np.linspace(0,1,n)\n",
    "y = np.linspace(0,1,n) \n",
    "\n",
    "sigma_N = 0.1; mu_N = 0 #change for value of sigma_N to appropriate values\n",
    "z = FrankeFunction(x,y) + sigma_N*np.random.randn(n)\t#adding noise to the dataset\n",
    "\n",
    "#gives a weird graph which does not bahve as expected\n",
    "#Because bootsatrap is not implemented?\n",
    "complexity = []\n",
    "MSE_train_set = []\n",
    "MSE_test_set = []\n",
    "\n",
    "\n",
    "X = create_X(x, y, 40)\n",
    "ols_beta, MSE_train, MSE_test = OLS_solver(X,z)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#not working as intended\n",
    "for i in range(2,30): #goes out of range for high i?\n",
    "\t\n",
    "\tX = create_X(x, y, i)\n",
    "\tols_beta, MSE_train, MSE_test = OLS_solver(X,z)\n",
    "\tcomplexity.append(i)\n",
    "\tMSE_train_set.append(MSE_train)\n",
    "\tMSE_test_set.append(MSE_test)\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(complexity,MSE_train_set, label =\"train\")  \n",
    "plt.plot(complexity,MSE_test_set, label =\"test\")  \n",
    " \n",
    "\n",
    "plt.xlabel(\"complexity\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.title(\"Plot of the MSE as a function of complexity of the model\")\n",
    "plt.legend()\n",
    "plt.grid()     \n",
    "#plt.savefig('Task2plot(n='+str(n)+').pdf')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator, FormatStrFormatter\n",
    "import numpy as np\n",
    "from random import random, seed\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import statistics\n",
    "from time import time\n",
    "from scipy.stats import norm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# FrankeFunction: a two-variables function to create the dataset of our vanilla problem\n",
    "def FrankeFunction(x,y): #code from task\n",
    "\tterm1 = 0.75*np.exp(-(0.25*(9*x-2)**2) - 0.25*((9*y-2)**2))\n",
    "\tterm2 = 0.75*np.exp(-((9*x+1)**2)/49.0 - 0.1*(9*y+1))\n",
    "\tterm3 = 0.5*np.exp(-(9*x-7)**2/4.0 - 0.25*((9*y-3)**2))\n",
    "\tterm4 = -0.2*np.exp(-(9*x-4)**2 - (9*y-7)**2)\n",
    "\treturn term1 + term2 + term3 + term4\n",
    "\n",
    "# Error analysis: MSE and R2 score\n",
    "def R2(y_data, y_model): #week 35 exercise\n",
    "    return 1 - np.sum((y_data - y_model) ** 2) / np.sum((y_data - np.mean(y_data)) ** 2)\n",
    "def MSE(y_data,y_model):\n",
    "    n = np.size(y_model)\n",
    "    return np.sum((y_data-y_model)**2)/n\n",
    "\n",
    "# SVD theorem\n",
    "def SVD(A): #week35 SVD change to week 36\n",
    "    U, S, VT = np.linalg.svd(A,full_matrices=True)\n",
    "    D = np.zeros((len(U),len(VT)))\n",
    "    print(\"shape D= \", np.shape(D))\n",
    "    print(\"Shape S= \",np.shape(S))\n",
    "    print(\"lenVT =\",len(VT))\n",
    "    print(\"lenU =\",len(U))\n",
    "    D = np.eye(len(U),len(VT))*S\n",
    "    \"\"\"\n",
    "    for i in range(0,VT.shape[0]): #was len(VT)\n",
    "        D[i,i]=S[i]\n",
    "        print(\"i=\",i)\"\"\"\n",
    "    return U @ D @ VT\n",
    "\n",
    "#Makes a 3d plot of the franke function\n",
    "def Plot_franke_function(): #code from task\n",
    "\tfig = plt.figure()\n",
    "\tax = fig.gca(projection=\"3d\")\n",
    "\n",
    "\t# Make data.\n",
    "\tx = np.arange(0, 1, 0.05)\n",
    "\ty = np.arange(0, 1, 0.05)\n",
    "\tx, y = np.meshgrid(x,y)\n",
    "\tz = FrankeFunction(x, y)\n",
    "\n",
    "\t# Plot the surface.\n",
    "\tsurf = ax.plot_surface(x, y, z, cmap=cm.coolwarm,\n",
    "\tlinewidth=0, antialiased=False)\n",
    "\n",
    "\t# Customize the z axis.\n",
    "\tax.set_zlim(-0.10, 1.40)\n",
    "\tax.zaxis.set_major_locator(LinearLocator(10))\n",
    "\tax.zaxis.set_major_formatter(FormatStrFormatter('%.02f'))\n",
    "\n",
    "\t# Add a color bar which maps values to colors.\n",
    "\tfig.colorbar(surf, shrink=0.5, aspect=5)\n",
    "\tplt.show()\n",
    "\n",
    "#Setting up design matrix from week 35-36 lecture slides\n",
    "def create_X(x, y, n):\n",
    "\tif len(x.shape) > 1:\n",
    "\t\tx = np.ravel(x)\n",
    "\t\ty = np.ravel(y)\n",
    "\n",
    "\tN = len(x)\n",
    "\tl = int((n+1)*(n+2)/2)\t\t# Number of elements in beta, number of feutures (order-degree of polynomial)\n",
    "\tX = np.ones((N,l))\n",
    "\n",
    "\tfor i in range(1,n+1):\n",
    "\t\tq = int((i)*(i+1)/2)\n",
    "\t\tfor k in range(i+1):\n",
    "\t\t\tX[:,q+k] = (x**(i-k))*(y**k)\n",
    "\n",
    "\treturn X\n",
    "\n",
    "def Split_and_Scale(X,z,test_size=0.2, scale=True):\n",
    "\n",
    "    #Splitting training and test data\n",
    "    X_train, X_test, z_train, z_test = train_test_split(X, z, test_size=test_size)\n",
    "\n",
    "    #scaling the the input with standardscalar (week35)\n",
    "    if scale==True:\n",
    "        scaler=StandardScaler()\n",
    "        scaler.fit(X_train)\n",
    "\n",
    "        X_train = scaler.transform(X_train)\n",
    "\n",
    "        #used to scale train and test --> #why do you do it manually instead of using the Standard scaler?\n",
    "        \"\"\"z_mean = np.mean(z_train)\n",
    "        z_sigma = np.std(z_train)\n",
    "\n",
    "        z_train = (z_train- z_mean)/z_sigma\"\"\"\n",
    "\n",
    "        #Scaling test data\n",
    "        X_test = scaler.transform(X_test)\n",
    "        #z_test = (z_test- z_mean)/z_sigma\n",
    "      \n",
    "    return X_train, X_test, z_train, z_test\n",
    "\n",
    "def OLS_solver(X_train, X_test, z_train, z_test):\n",
    "\n",
    "\t# Calculating Beta Ordinary Least Square with matrix inversion\n",
    "\tols_beta = np.linalg.pinv(X_train.T @ X_train) @ X_train.T @ z_train #psudoinverse\n",
    "  \n",
    "\tz_tilde = X_train @ ols_beta\n",
    "\tz_predict = X_test @ ols_beta\n",
    "\n",
    "\t#beta_ols_variance = z_sigma**2 @ np.linalg.pinv(X_train.T @ X_train) #Agree correct?\n",
    "\treturn ols_beta, z_tilde, z_predict\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Task 1 comments:\n",
    "We still need to find the variance of beta.\n",
    "\n",
    "\n",
    "\n",
    "What to plot? (use mesh, x,y, z and z_tilda?)\n",
    "How to find confidence? y-y_tilda = sigma\n",
    "Sima is the stardard deviation of the error?\n",
    "\n",
    "print(\"Beta(ols) variance:\") //variance of beta? or = np.mean( np.var(y_pred, axis=1, keepdims=True) )\n",
    "print(statistics.variance(ols_beta))\n",
    "\n",
    "\n",
    "plt.plot(X_train,ztilde, label =\"u values\")   \n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "#------Task 1------\n",
    "\n",
    "# Create vanilla dataset:\n",
    "n = 1000\n",
    "\n",
    "x = np.sort(np.random.uniform(0, 1, n))\n",
    "y = np.sort(np.random.uniform(0, 1, n))\n",
    "#x, y = np.meshgrid(x,y)\n",
    "\n",
    "sigma_N = 0.1; mu_N = 0 #change for value of sigma_N to appropriate values\n",
    "z = FrankeFunction(x,y) + np.random.normal(mu_N,sigma_N,n)#adding noise to the dataset\n",
    "print(np.max(z),np.min(z))\n",
    "Plot_franke_function()\n",
    "\n",
    "degree=5\n",
    "\n",
    "# OLS\n",
    "X = create_X(x, y, degree)\n",
    "X_train, X_test, z_train, z_test = Split_and_Scale(X,z) #StardardScaler, test_size=0.2, scale=true\n",
    "ols_beta, z_tilde,z_predict = OLS_solver(X_train, X_test, z_train, z_test)\n",
    "\n",
    "print(\"Training MSE\", MSE(z_train,z_tilde))\n",
    "print(\"Test MSE\", MSE(z_test,z_predict))\n",
    "print(\"-------------------------------------\")\n",
    "print(\"Training R2\", R2(z_train,z_tilde))\n",
    "print(\"Test R2\", R2(z_test,z_predict))\n",
    "\n",
    "# Missing confidence interval\n",
    "# I would plot the data anyway\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx, ny = (3, 2)\n",
    "print(nx,ny)\n",
    "x = np.linspace(0, 1, nx)\n",
    "y = np.linspace(0, 1, ny)\n",
    "xv, yv = np.meshgrid(x, y)\n",
    "print(x)\n",
    "print(y)\n",
    "print(xv)\n",
    "print(yv)\n",
    "xv, yv = np.meshgrid(x, y, sparse=True)  # make sparse output arrays\n",
    "print(xv)\n",
    "print(yv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array([[0. , 0.5, 1. ],\n",
    "       [0. , 0.5, 1. ]])\n",
    ">>> yv\n",
    "array([[0.,  0.,  0.],\n",
    "       [1.,  1.,  1.]])\n",
    ">>> xv, yv = np.meshgrid(x, y, sparse=True)  # make sparse output arrays\n",
    ">>> xv\n",
    "array([[0. ,  0.5,  1. ]])\n",
    ">>> yv\n",
    "array([[0.],\n",
    "       [1.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator, FormatStrFormatter\n",
    "import numpy as np\n",
    "from random import random, seed\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import statistics\n",
    "from time import time\n",
    "from scipy.stats import norm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# FrankeFunction: a two-variables function to create the dataset of our vanilla problem\n",
    "def FrankeFunction(x,y): #code from task\n",
    "\tterm1 = 0.75*np.exp(-(0.25*(9*x-2)**2) - 0.25*((9*y-2)**2))\n",
    "\tterm2 = 0.75*np.exp(-((9*x+1)**2)/49.0 - 0.1*(9*y+1))\n",
    "\tterm3 = 0.5*np.exp(-(9*x-7)**2/4.0 - 0.25*((9*y-3)**2))\n",
    "\tterm4 = -0.2*np.exp(-(9*x-4)**2 - (9*y-7)**2)\n",
    "\treturn term1 + term2 + term3 + term4\n",
    " \n",
    "# 3D plot of FrankeFunction\n",
    "def Plot_franke_function(): #code from task\n",
    "  fig = plt.figure()\n",
    "  ax = fig.gca(projection=\"3d\")\n",
    "\n",
    "  # Make data.\n",
    "  x = np.arange(0, 1, 0.05)\n",
    "  y = np.arange(0, 1, 0.05)\n",
    "  x, y = np.meshgrid(x,y)\n",
    "  z = FrankeFunction(x, y)\n",
    "\n",
    "  # Plot the surface.\n",
    "  surf = ax.plot_surface(x, y, z, cmap=cm.coolwarm,\n",
    "  linewidth=0, antialiased=False)\n",
    "\n",
    "  # Customize the z axis.\n",
    "  ax.set_zlim(-0.10, 1.40)\n",
    "  ax.zaxis.set_major_locator(LinearLocator(10))\n",
    "  ax.zaxis.set_major_formatter(FormatStrFormatter('%.02f'))\n",
    "\n",
    "  # Add a color bar which maps values to colors.\n",
    "  fig.colorbar(surf, shrink=0.5, aspect=5)\n",
    "  plt.show()\n",
    "\n",
    "# Error analysis: MSE and R2 score\n",
    "def R2(y_data, y_model): #week 35 exercise\n",
    "    return 1 - np.sum((y_data - y_model) ** 2) / np.sum((y_data - np.mean(y_data)) ** 2)\n",
    "def MSE(y_data,y_model):\n",
    "    n = np.size(y_model)\n",
    "    return np.sum((y_data-y_model)**2)/n\n",
    "\n",
    "# SVD theorem\n",
    "def SVD(A): #week35 SVD change to week 36\n",
    "    U, S, VT = np.linalg.svd(A,full_matrices=True)\n",
    "    D = np.zeros((len(U),len(VT)))\n",
    "    print(\"shape D= \", np.shape(D))\n",
    "    print(\"Shape S= \",np.shape(S))\n",
    "    print(\"lenVT =\",len(VT))\n",
    "    print(\"lenU =\",len(U))\n",
    "    D = np.eye(len(U),len(VT))*S\n",
    "    \"\"\"\n",
    "    for i in range(0,VT.shape[0]): #was len(VT)\n",
    "        D[i,i]=S[i]\n",
    "        print(\"i=\",i)\"\"\"\n",
    "    return U @ D @ VT\n",
    "\n",
    "# Design matrix\n",
    "def create_X(x, y, n): # week 35-36 lecture slides\n",
    "\tif len(x.shape) > 1:\n",
    "\t\tx = np.ravel(x)\n",
    "\t\ty = np.ravel(y)\n",
    "\n",
    "\tN = len(x)\n",
    "\tl = int((n+1)*(n+2)/2)\t\t# Number of elements in beta, number of feutures (order-degree of polynomial)\n",
    "\tX = np.ones((N,l))\n",
    "\n",
    "\tfor i in range(1,n+1):\n",
    "\t\tq = int((i)*(i+1)/2)\n",
    "\t\tfor k in range(i+1):\n",
    "\t\t\tX[:,q+k] = (x**(i-k))*(y**k)\n",
    "\n",
    "\treturn X\n",
    "\n",
    "def Split_and_Scale(X,z,test_size=0.2, scale=True):\n",
    "\n",
    "    #Splitting training and test data\n",
    "    X_train, X_test, z_train, z_test = train_test_split(X, z, test_size=test_size)\n",
    "\n",
    "    #scaling the the input with standardscalar (week35)\n",
    "    if scale==True:\n",
    "        scaler_X = StandardScaler(with_std=False)\n",
    "        scaler_X.fit(X_train)\n",
    "        X_train = scaler_X.transform(X_train)\n",
    "        X_test = scaler_X.transform(X_test)\n",
    "\n",
    "        scaler_z = StandardScaler(with_std=False)\n",
    "        #scaler_z.fit(z_train)\n",
    "        z_train = np.squeeze(scaler_z.fit_transform(z_train.reshape(-1, 1)))\n",
    "        z_test = np.squeeze(scaler_z.transform(z_test.reshape(-1, 1)))\n",
    "      \n",
    "        #used to scale train and test --> #why do you do it manually instead of using the Standard scaler?\n",
    "        \"\"\"z_mean = np.mean(z_train)\n",
    "        z_sigma = np.std(z_train)\n",
    "        z_train = (z_train- z_mean)/z_sigma\"\"\"\n",
    "        #z_test = (z_test- z_mean)/z_sigma\n",
    "      \n",
    "    return X_train, X_test, z_train, z_test\n",
    "\n",
    "def OLS_solver(X_train, X_test, z_train, z_test):\n",
    "\n",
    "\t# Calculating Beta Ordinary Least Square with matrix inversion\n",
    "\tols_beta = np.linalg.pinv(X_train.T @ X_train) @ X_train.T @ z_train #psudoinverse\n",
    "  \n",
    "\tz_tilde = X_train @ ols_beta\n",
    "\tz_predict = X_test @ ols_beta\n",
    "\n",
    "\t#beta_ols_variance = z_sigma**2 @ np.linalg.pinv(X_train.T @ X_train) #Agree correct?\n",
    "\treturn ols_beta, z_tilde, z_predict\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Task 1 comments:\n",
    "We still need to find the variance of beta.\n",
    "\n",
    "\n",
    "\n",
    "What to plot? (use mesh, x,y, z and z_tilda?)\n",
    "How to find confidence? y-y_tilda = sigma\n",
    "Sima is the stardard deviation of the error?\n",
    "\n",
    "print(\"Beta(ols) variance:\") //variance of beta? or = np.mean( np.var(y_pred, axis=1, keepdims=True) )\n",
    "print(statistics.variance(ols_beta))\n",
    "\n",
    "\n",
    "plt.plot(X_train,ztilde, label =\"u values\")   \n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "#------Task 1------\n",
    "\n",
    "# Create vanilla dataset:\n",
    "n = 1000\n",
    "\n",
    "x = np.linspace(0,1,n)\n",
    "y = np.linspace(0,1,n) \n",
    "\n",
    "sigma_N = 0.1; mu_N = 0 #change for value of sigma_N to appropriate values\n",
    "z = FrankeFunction(x,y) + np.random.randn(n)\t#adding noise to the dataset\n",
    "\n",
    "degree=5\n",
    "\n",
    "# OLS\n",
    "X = create_X(x, y, degree)\n",
    "X_train, X_test, z_train, z_test = Split_and_Scale(X,z) #StardardScaler, test_size=0.2, scale=true\n",
    "ols_beta, z_tilde,z_predict = OLS_solver(X_train, X_test, z_train, z_test)\n",
    "\n",
    "print(\"Training MSE\", MSE(z_train,z_tilde))\n",
    "print(\"Test MSE\", MSE(z_test,z_predict))\n",
    "print(\"-------------------------------------\")\n",
    "print(\"Training R2\", R2(z_train,z_tilde))\n",
    "print(\"Test R2\", R2(z_test,z_predict))\n",
    "\n",
    "# Missing confidence interval\n",
    "# I would plot the data anyway\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40,)\n",
      "(40, 1)\n",
      "(8, 1) (8, 100)\n",
      "Polynomial degree: 0\n",
      "Error: 0.3214960170351912\n",
      "Bias^2: 0.3123314713548606\n",
      "Var: 0.009164545680330616\n",
      "0.3214960170351912 >= 0.3123314713548606 + 0.009164545680330616 = 0.3214960170351912\n",
      "(8, 1) (8, 100)\n",
      "Polynomial degree: 1\n",
      "Error: 0.08426840630693411\n",
      "Bias^2: 0.07968918676726028\n",
      "Var: 0.004579219539673834\n",
      "0.08426840630693411 >= 0.07968918676726028 + 0.004579219539673834 = 0.08426840630693411\n",
      "(8, 1) (8, 100)\n",
      "Polynomial degree: 2\n",
      "Error: 0.10398646080125036\n",
      "Bias^2: 0.10077114273548984\n",
      "Var: 0.00321531806576051\n",
      "0.10398646080125036 >= 0.10077114273548984 + 0.00321531806576051 = 0.10398646080125035\n",
      "(8, 1) (8, 100)\n",
      "Polynomial degree: 3\n",
      "Error: 0.06547790180152356\n",
      "Bias^2: 0.06208238634231951\n",
      "Var: 0.003395515459204095\n",
      "0.06547790180152356 >= 0.06208238634231951 + 0.003395515459204095 = 0.0654779018015236\n",
      "(8, 1) (8, 100)\n",
      "Polynomial degree: 4\n",
      "Error: 0.0684451941400944\n",
      "Bias^2: 0.06453579006728317\n",
      "Var: 0.00390940407281122\n",
      "0.0684451941400944 >= 0.06453579006728317 + 0.00390940407281122 = 0.0684451941400944\n",
      "(8, 1) (8, 100)\n",
      "Polynomial degree: 5\n",
      "Error: 0.05227921801205693\n",
      "Bias^2: 0.048187277304302945\n",
      "Var: 0.004091940707753993\n",
      "0.05227921801205693 >= 0.048187277304302945 + 0.004091940707753993 = 0.05227921801205694\n",
      "(8, 1) (8, 100)\n",
      "Polynomial degree: 6\n",
      "Error: 0.03781367141738895\n",
      "Bias^2: 0.033657685071527596\n",
      "Var: 0.0041559863458613695\n",
      "0.03781367141738895 >= 0.033657685071527596 + 0.0041559863458613695 = 0.037813671417388964\n",
      "(8, 1) (8, 100)\n",
      "Polynomial degree: 7\n",
      "Error: 0.027609773491022168\n",
      "Bias^2: 0.022999498260365965\n",
      "Var: 0.004610275230656189\n",
      "0.027609773491022168 >= 0.022999498260365965 + 0.004610275230656189 = 0.027609773491022154\n",
      "(8, 1) (8, 100)\n",
      "Polynomial degree: 8\n",
      "Error: 0.01735584819559231\n",
      "Bias^2: 0.010331721306655061\n",
      "Var: 0.007024126888937246\n",
      "0.01735584819559231 >= 0.010331721306655061 + 0.007024126888937246 = 0.017355848195592306\n",
      "(8, 1) (8, 100)\n",
      "Polynomial degree: 9\n",
      "Error: 0.026605727637186757\n",
      "Bias^2: 0.010018312644140812\n",
      "Var: 0.016587414993045953\n",
      "0.026605727637186757 >= 0.010018312644140812 + 0.016587414993045953 = 0.026605727637186764\n",
      "(8, 1) (8, 100)\n",
      "Polynomial degree: 10\n",
      "Error: 0.021592704588010762\n",
      "Bias^2: 0.010516485576655746\n",
      "Var: 0.011076219011355012\n",
      "0.021592704588010762 >= 0.010516485576655746 + 0.011076219011355012 = 0.02159270458801076\n",
      "(8, 1) (8, 100)\n",
      "Polynomial degree: 11\n",
      "Error: 0.07160048164244402\n",
      "Bias^2: 0.014436800088952916\n",
      "Var: 0.05716368155349111\n",
      "0.07160048164244402 >= 0.014436800088952916 + 0.05716368155349111 = 0.07160048164244402\n",
      "(8, 1) (8, 100)\n",
      "Polynomial degree: 12\n",
      "Error: 0.11547777218941857\n",
      "Bias^2: 0.016285782696092845\n",
      "Var: 0.09919198949332578\n",
      "0.11547777218941857 >= 0.016285782696092845 + 0.09919198949332578 = 0.11547777218941863\n",
      "(8, 1) (8, 100)\n",
      "Polynomial degree: 13\n",
      "Error: 0.22842468702147456\n",
      "Bias^2: 0.019754165271820806\n",
      "Var: 0.20867052174965375\n",
      "0.22842468702147456 >= 0.019754165271820806 + 0.20867052174965375 = 0.22842468702147456\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.utils import resample\n",
    "\n",
    "np.random.seed(2018)\n",
    "\n",
    "n = 40\n",
    "n_boostraps = 100\n",
    "maxdegree = 14\n",
    "\n",
    "\n",
    "# Make data set.\n",
    "x = np.linspace(-3, 3, n)\n",
    "print(x.shape)\n",
    "x=x.reshape(-1, 1)\n",
    "print(x.shape)\n",
    "y = np.exp(-x**2) + 1.5 * np.exp(-(x-2)**2)+ np.random.normal(0, 0.1, x.shape)\n",
    "error = np.zeros(maxdegree)\n",
    "bias = np.zeros(maxdegree)\n",
    "variance = np.zeros(maxdegree)\n",
    "polydegree = np.zeros(maxdegree)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "\n",
    "for degree in range(maxdegree):\n",
    "    model = make_pipeline(PolynomialFeatures(degree=degree), LinearRegression(fit_intercept=False))\n",
    "    y_pred = np.empty((y_test.shape[0], n_boostraps))\n",
    "    for i in range(n_boostraps):\n",
    "        x_, y_ = resample(x_train, y_train)\n",
    "        y_pred[:, i] = model.fit(x_, y_).predict(x_test).ravel()\n",
    "\n",
    "    polydegree[degree] = degree\n",
    "    print(y_test.shape, y_pred.shape)\n",
    "    error[degree] = np.mean( np.mean((y_test - y_pred)**2, axis=1, keepdims=True) )\n",
    "    bias[degree] = np.mean( (y_test - np.mean(y_pred, axis=1, keepdims=True))**2 )\n",
    "    variance[degree] = np.mean( np.var(y_pred, axis=1, keepdims=True) )\n",
    "    print('Polynomial degree:', degree)\n",
    "    print('Error:', error[degree])\n",
    "    print('Bias^2:', bias[degree])\n",
    "    print('Var:', variance[degree])\n",
    "    print('{} >= {} + {} = {}'.format(error[degree], bias[degree], variance[degree], bias[degree]+variance[degree]))\n",
    "\n",
    "plt.plot(polydegree, error, label='Error')\n",
    "plt.plot(polydegree, bias, label='bias')\n",
    "plt.plot(polydegree, variance, label='Variance')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
