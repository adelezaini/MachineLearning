{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The MIT License (MIT)\n",
    "#\n",
    "# Copyright © 2021 Fridtjof Gjengset, Adele Zaini, Gaute Holen\n",
    "#\n",
    "# Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated\n",
    "# documentation files (the “Software”), to deal in the Software without restriction, including without limitation the\n",
    "# rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software,\n",
    "# and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n",
    "#\n",
    "# The above copyright notice and this permission notice shall be included in all copies or substantial portions of\n",
    "# the Software. THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT\n",
    "# LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT\n",
    "# SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF\n",
    "# CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS\n",
    "# IN THE SOFTWARE.\n",
    "\n",
    "import numpy as np\n",
    "from random import random, seed\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator, FormatStrFormatter\n",
    "\n",
    "\n",
    "# FrankeFunction: a two-variables function to create the dataset of our vanilla problem\n",
    "def FrankeFunction(x,y): #code from task\n",
    "\tterm1 = 0.75*np.exp(-(0.25*(9*x-2)**2) - 0.25*((9*y-2)**2))\n",
    "\tterm2 = 0.75*np.exp(-((9*x+1)**2)/49.0 - 0.1*(9*y+1))\n",
    "\tterm3 = 0.5*np.exp(-(9*x-7)**2/4.0 - 0.25*((9*y-3)**2))\n",
    "\tterm4 = -0.2*np.exp(-(9*x-4)**2 - (9*y-7)**2)\n",
    "\treturn term1 + term2 + term3 + term4\n",
    " \n",
    "# 3D plot of FrankeFunction\n",
    "def Plot_FrankeFunction(x,y,z, title=\"Dataset\"): #code from task\n",
    "    fig = plt.figure()\n",
    "    ax = fig.gca(projection=\"3d\")\n",
    "\n",
    "    # Plot the surface.\n",
    "    surf = ax.plot_surface(x, y, z, cmap=cm.coolwarm, linewidth=0, antialiased=False)\n",
    "\n",
    "    # Customize the z axis.\n",
    "    ax.set_zlim(-0.10, 1.40)\n",
    "    ax.zaxis.set_major_locator(LinearLocator(10))\n",
    "    ax.zaxis.set_major_formatter(FormatStrFormatter('%.02f'))\n",
    "\n",
    "    # Add a color bar which maps values to colors.\n",
    "    fig.colorbar(surf, shrink=0.5, aspect=5)\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "# Error analysis: MSE and R2 score\n",
    "def R2(y_data, y_model): #week 35 exercise\n",
    "    return 1 - np.sum((y_data - y_model) ** 2) / np.sum((y_data - np.mean(y_data)) ** 2)\n",
    "def MSE(y_data,y_model):\n",
    "    n = np.size(y_model)\n",
    "    return np.sum((y_data-y_model)**2)/n\n",
    "\n",
    "# SVD theorem\n",
    "def SVD(A): #week35 SVD change to week 36\n",
    "    U, S, VT = np.linalg.svd(A,full_matrices=True)\n",
    "    D = np.zeros((len(U),len(VT)))\n",
    "    print(\"shape D= \", np.shape(D))\n",
    "    print(\"Shape S= \",np.shape(S))\n",
    "    print(\"lenVT =\",len(VT))\n",
    "    print(\"lenU =\",len(U))\n",
    "    D = np.eye(len(U),len(VT))*S\n",
    "    \"\"\"\n",
    "    for i in range(0,VT.shape[0]): #was len(VT)\n",
    "        D[i,i]=S[i]\n",
    "        print(\"i=\",i)\"\"\"\n",
    "    return U @ D @ VT\n",
    "\n",
    "# Design matrix\n",
    "def create_X(x, y, n): # week 35-36 lecture slides\n",
    "\tif len(x.shape) > 1:\n",
    "\t\tx = np.ravel(x)\n",
    "\t\ty = np.ravel(y)\n",
    "\n",
    "\tN = len(x)\n",
    "\tl = int((n+1)*(n+2)/2)\t\t# Number of elements in beta, number of feutures (order-degree of polynomial)\n",
    "\tX = np.ones((N,l))\n",
    "\n",
    "\tfor i in range(1,n+1):\n",
    "\t\tq = int((i)*(i+1)/2)\n",
    "\t\tfor k in range(i+1):\n",
    "\t\t\tX[:,q+k] = (x**(i-k))*(y**k)\n",
    "\n",
    "\treturn X\n",
    "  \n",
    "# Splitting and rescaling data (rescaling is optional)\n",
    "# Default values: 20% of test data and the scaler is StandardScaler without std.dev.\n",
    "def Split_and_Scale(X,z,test_size=0.2, scale=True):\n",
    "\n",
    "    #Splitting training and test data\n",
    "    X_train, X_test, z_train, z_test = train_test_split(X, z, test_size=test_size)\n",
    "\n",
    "    # Rescaling X and z (optional)\n",
    "    if scale==True:\n",
    "        scaler_X = StandardScaler(with_std=False)\n",
    "        scaler_X.fit(X_train)\n",
    "        X_train = scaler_X.transform(X_train)\n",
    "        X_test = scaler_X.transform(X_test)\n",
    "\n",
    "        scaler_z = StandardScaler(with_std=False)\n",
    "        z_train = np.squeeze(scaler_z.fit_transform(z_train.reshape(-1, 1)))\n",
    "        z_test = np.squeeze(scaler_z.transform(z_test.reshape(-1, 1)))\n",
    "      \n",
    "    return X_train, X_test, z_train, z_test\n",
    "\n",
    "# OLS equation\n",
    "def OLS_solver(X_train, X_test, z_train, z_test):\n",
    "\n",
    "\t# Calculating Beta Ordinary Least Square with matrix inversion\n",
    "\tols_beta = np.linalg.pinv(X_train.T @ X_train) @ X_train.T @ z_train #psudoinverse\n",
    "  \n",
    "\tz_tilde = X_train @ ols_beta\n",
    "\tz_predict = X_test @ ols_beta\n",
    "\n",
    "\t#beta_ols_variance = z_sigma**2 @ np.linalg.pinv(X_train.T @ X_train) #Agree correct?\n",
    "\treturn ols_beta, z_tilde, z_predict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "degree=5\n",
    "\n",
    "# Create vanilla dataset:\n",
    "np.random.seed(9)\n",
    "\n",
    "n = 1000\n",
    "\n",
    "x = np.linspace(0,1,n)\n",
    "y = np.linspace(0,1,n)\n",
    "print(x[1:10])\n",
    "print(y[1:10])\n",
    "x, y = np.meshgrid(x,y)\n",
    "\n",
    "sigma_N = 0.1; mu_N = 0 #change for value of sigma_N to appropriate values\n",
    "z = FrankeFunction(x,y) +mu_N+sigma_N*np.random.randn(n,n)#+ np.random.normal(mu_N,sigma_N,n**2)\t#adding noise to the dataset\n",
    "\n",
    "print(z.shape)\n",
    "Plot_FrankeFunction(x,y,z)\n",
    "\n",
    "print(z)\n",
    "# OLS\n",
    "X = create_X(x, y, degree)\n",
    "print(\"X\", X.shape)\n",
    "z=np.ravel(z)\n",
    "X_train, X_test, z_train, z_test = Split_and_Scale(X,z) #StardardScaler, test_size=0.2, scale=true\n",
    "print(z_test.shape)\n",
    "print(z_train.shape)\n",
    "ols_beta, z_tilde,z_predict = OLS_solver(X_train, X_test, z_train, z_test)\n",
    "\n",
    "\n",
    "print(\"Training MSE\", MSE(z_train,z_tilde))\n",
    "print(\"Test MSE\", MSE(z_test,z_predict))\n",
    "print(\"-------------------------------------\")\n",
    "print(\"Training R2\", R2(z_train,z_tilde))\n",
    "print(\"Test R2\", R2(z_test,z_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "degree=5\n",
    "\n",
    "# Create vanilla dataset:\n",
    "np.random.seed(3155)\n",
    "\n",
    "n = 1000\n",
    "\n",
    "x = np.linspace(0,1,n)\n",
    "y = np.linspace(0,1,n) \n",
    "x, y = np.meshgrid(x,y)\n",
    "\n",
    "sigma_N = 0.1; mu_N = 0 #change for value of sigma_N to appropriate values\n",
    "z = FrankeFunction(x,y) +mu_N+sigma_N*np.random.randn(n,n)#+ np.random.normal(mu_N,sigma_N,n**2)  #adding noise to the dataset\n",
    "\n",
    "Plot_FrankeFunction(x,y,z, title=\"Noisy dataset\")\n",
    "\n",
    "# OLS\n",
    "X = create_X(x, y, degree)\n",
    "X=pd.DataFrame(X)\n",
    "display(X)\n",
    "X_train, X_test, z_train, z_test = Split_and_Scale(X,np.ravel(z)) #StardardScaler, test_size=0.2, scale=true\n",
    "ols_beta, z_tilde,z_predict = OLS_solver(X_train, X_test, z_train, z_test)\n",
    "print(z_test)\n",
    "print(ols_beta)\n",
    "ols_beta=pd.DataFrame(ols_beta)\n",
    "display(ols_beta)\n",
    "\n",
    "print(\"Training MSE\", MSE(z_train,z_tilde))\n",
    "print(\"Test MSE\", MSE(z_test,z_predict))\n",
    "print(\"-------------------------------------\")\n",
    "print(\"Training R2\", R2(z_train,z_tilde))\n",
    "print(\"Test R2\", R2(z_test,z_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.linear_model as skl\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import math\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator, FormatStrFormatter\n",
    "\n",
    "np.random.seed(2204)\n",
    "\n",
    "## part a\n",
    "def FrankeFunction(x,y):\n",
    "    term1 = 0.75*np.exp(-(0.25*(9*x-2)**2) - 0.25*((9*y-2)**2))\n",
    "    term2 = 0.75*np.exp(-((9*x+1)**2)/49.0 - 0.1*(9*y+1))\n",
    "    term3 = 0.5*np.exp(-(9*x-7)**2/4.0 - 0.25*((9*y-3)**2))\n",
    "    term4 = -0.2*np.exp(-(9*x-4)**2 - (9*y-7)**2)\n",
    "    return term1 + term2 + term3 + term4\n",
    "\n",
    "def Design_Matrix_X(x, y, n):\n",
    "\tN = len(x)\n",
    "\tl = int((n+1)*(n+2)/2)\t\t\n",
    "\tX = np.ones((N,l))\n",
    "\n",
    "\tfor i in range(1,n+1):\n",
    "\t\tq = int((i)*(i+1)/2)\n",
    "\t\tfor k in range(i+1):\n",
    "\t\t\tX[:,q+k] = x**(i-k) * y**k\n",
    "\n",
    "\treturn X\n",
    "\n",
    "n_x=1000\n",
    "m=5\n",
    "\n",
    "x = np.random.uniform(0, 1, n_x)\n",
    "y = np.random.uniform(0, 1, n_x)\n",
    "\n",
    "z = FrankeFunction(x, y)\n",
    "\n",
    "#print(x)\n",
    "\n",
    "n = int(len(x))\n",
    "z_1 = z +0.01*np.random.randn(n)\n",
    "\n",
    "X= Design_Matrix_X(x,y,n=m)\n",
    "DesignMatrix = pd.DataFrame(X)\n",
    "#print(DesignMatrix)\n",
    "\n",
    "a = np.linalg.matrix_rank(X) #we check it is not a singular matrix\n",
    "print(a)\n",
    "\n",
    "beta = np.linalg.inv(X.T.dot(X)).dot(X.T).dot(z_1)\n",
    "ztilde = X @ beta\n",
    "#print(beta)\n",
    "\n",
    "beta1 = skl.LinearRegression().fit(X,z_1) #function .fit fits linear models\n",
    "ztilde1 = beta1.predict(X)\n",
    "\n",
    "#print(ztilde)\n",
    "#print('--')\n",
    "#print(ztilde1)\n",
    "\n",
    "var_beta_OLS = 1*np.linalg.inv(X.T.dot(X))\n",
    "#print(var_beta_OLS)\n",
    "var = pd.DataFrame(var_beta_OLS)\n",
    "#print(var)\n",
    "var_diag=np.diag(var_beta_OLS)\n",
    "#print(var_diag)\n",
    "\n",
    "l1_OLS = beta - 1.96*np.sqrt(var_diag)/(X.shape[0])\n",
    "l2_OLS = beta + 1.96*np.sqrt(var_diag)/(X.shape[0])\n",
    "print(l1_OLS)\n",
    "print(l2_OLS)\n",
    "\n",
    "def MSE (ydata, ymodel):\n",
    "    n = np.size(ymodel)\n",
    "    y = (ydata - ymodel).T@(ydata - ymodel)\n",
    "    y = y/n\n",
    "    return y\n",
    "\n",
    "def R2 (ydata, ymodel):\n",
    "    return 1-((ydata-ymodel).T@(ydata-ymodel))/((ydata-np.mean(ydata)).T@(ydata-np.mean(ydata)))\n",
    "\n",
    "\n",
    "print(MSE(z_1,ztilde))\n",
    "print(R2(z_1,ztilde))\n",
    "\n",
    "\n",
    "print(\"Mean squared error: %.2f\" % mean_squared_error(z_1, ztilde))\n",
    "print('Variance score: %.2f' % r2_score(z_1, ztilde))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from random import random, seed\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator, FormatStrFormatter\n",
    "\n",
    "\n",
    "# FrankeFunction: a two-variables function to create the dataset of our vanilla problem\n",
    "def FrankeFunction(x,y): #code from task\n",
    "\tterm1 = 0.75*np.exp(-(0.25*(9*x-2)**2) - 0.25*((9*y-2)**2))\n",
    "\tterm2 = 0.75*np.exp(-((9*x+1)**2)/49.0 - 0.1*(9*y+1))\n",
    "\tterm3 = 0.5*np.exp(-(9*x-7)**2/4.0 - 0.25*((9*y-3)**2))\n",
    "\tterm4 = -0.2*np.exp(-(9*x-4)**2 - (9*y-7)**2)\n",
    "\treturn term1 + term2 + term3 + term4\n",
    " \n",
    "# 3D plot of FrankeFunction\n",
    "def Plot_FrankeFunction(): #code from task\n",
    "  fig = plt.figure()\n",
    "  ax = fig.gca(projection=\"3d\")\n",
    "\n",
    "  # Make data.\n",
    "  x = np.arange(0, 1, 0.05)\n",
    "  y = np.arange(0, 1, 0.05)\n",
    "  x, y = np.meshgrid(x,y)\n",
    "  z = FrankeFunction(x, y)\n",
    "\n",
    "  # Plot the surface.\n",
    "  surf = ax.plot_surface(x, y, z, cmap=cm.coolwarm,\n",
    "  linewidth=0, antialiased=False)\n",
    "\n",
    "  # Customize the z axis.\n",
    "  ax.set_zlim(-0.10, 1.40)\n",
    "  ax.zaxis.set_major_locator(LinearLocator(10))\n",
    "  ax.zaxis.set_major_formatter(FormatStrFormatter('%.02f'))\n",
    "\n",
    "  # Add a color bar which maps values to colors.\n",
    "  fig.colorbar(surf, shrink=0.5, aspect=5)\n",
    "  plt.show()\n",
    "\n",
    "# Error analysis: MSE and R2 score\n",
    "def R2(y_data, y_model): #week 35 exercise\n",
    "    return 1 - np.sum((y_data - y_model) ** 2) / np.sum((y_data - np.mean(y_data)) ** 2)\n",
    "def MSE(y_data,y_model):\n",
    "    n = np.size(y_model)\n",
    "    return np.sum((y_data-y_model)**2)/n\n",
    "\n",
    "# SVD theorem\n",
    "def SVD(A): #week35 SVD change to week 36\n",
    "    U, S, VT = np.linalg.svd(A,full_matrices=True)\n",
    "    D = np.zeros((len(U),len(VT)))\n",
    "    print(\"shape D= \", np.shape(D))\n",
    "    print(\"Shape S= \",np.shape(S))\n",
    "    print(\"lenVT =\",len(VT))\n",
    "    print(\"lenU =\",len(U))\n",
    "    D = np.eye(len(U),len(VT))*S\n",
    "    \"\"\"\n",
    "    for i in range(0,VT.shape[0]): #was len(VT)\n",
    "        D[i,i]=S[i]\n",
    "        print(\"i=\",i)\"\"\"\n",
    "    return U @ D @ VT\n",
    "\n",
    "# Design matrix\n",
    "def create_X(x, y, n): # week 35-36 lecture slides\n",
    "\tif len(x.shape) > 1:\n",
    "\t\tx = np.ravel(x)\n",
    "\t\ty = np.ravel(y)\n",
    "\n",
    "\tN = len(x)\n",
    "\tl = int((n+1)*(n+2)/2)\t\t# Number of elements in beta, number of feutures (order-degree of polynomial)\n",
    "\tX = np.ones((N,l))\n",
    "\n",
    "\tfor i in range(1,n+1):\n",
    "\t\tq = int((i)*(i+1)/2)\n",
    "\t\tfor k in range(i+1):\n",
    "\t\t\tX[:,q+k] = (x**(i-k))*(y**k)\n",
    "\n",
    "\treturn X\n",
    "  \n",
    "# Splitting and rescaling data (rescaling is optional)\n",
    "# Default values: 20% of test data and the scaler is StandardScaler without std.dev.\n",
    "def Split_and_Scale(X,z,test_size=0.2, scale=True):\n",
    "\n",
    "    #Splitting training and test data\n",
    "    X_train, X_test, z_train, z_test = train_test_split(X, z, test_size=test_size)\n",
    "\n",
    "    # Rescaling X and z (optional)\n",
    "    if scale==True:\n",
    "        scaler_X = StandardScaler(with_std=False)\n",
    "        scaler_X.fit(X_train)\n",
    "        X_train = scaler_X.transform(X_train)\n",
    "        X_test = scaler_X.transform(X_test)\n",
    "\n",
    "        scaler_z = StandardScaler(with_std=False)\n",
    "        z_train = np.squeeze(scaler_z.fit_transform(z_train.reshape(-1, 1)))\n",
    "        z_test = np.squeeze(scaler_z.transform(z_test.reshape(-1, 1)))\n",
    "      \n",
    "    return X_train, X_test, z_train, z_test\n",
    "\n",
    "# OLS equation\n",
    "def OLS_solver(X_train, X_test, z_train, z_test):\n",
    "\n",
    "\t# Calculating Beta Ordinary Least Square with matrix inversion\n",
    "\tols_beta = np.linalg.pinv(X_train.T @ X_train) @ X_train.T @ z_train #psudoinverse\n",
    "  \n",
    "\tz_tilde = X_train @ ols_beta\n",
    "\tz_predict = X_test @ ols_beta\n",
    "\n",
    "\t#beta_ols_variance = z_sigma**2 @ np.linalg.pinv(X_train.T @ X_train) #Agree correct?\n",
    "\treturn ols_beta, z_tilde, z_predict\n",
    "\n",
    "def plot_ols_complexity(x, y, z, complexity = range(2,20)):\n",
    "\n",
    "    MSE_train_set = []\n",
    "    MSE_test_set = []\n",
    "\n",
    "    for degree in complexity:\n",
    "\n",
    "        X = create_X(x, y, degree)\n",
    "        X_train, X_test, z_train, z_test = Split_and_Scale(X,np.ravel(z)) #StardardScaler, test_size=0.2, scale=true\n",
    "        ols_beta, z_tilde,z_predict = OLS_solver(X_train, X_test, z_train, z_test)\n",
    "\n",
    "        MSE_train_set.append(MSE(z_train,z_tilde))\n",
    "        MSE_test_set.append(MSE(z_test,z_predict))\n",
    "\n",
    "    plt.plot(complexity,MSE_train_set, label =\"train\")  \n",
    "    plt.plot(complexity,MSE_test_set, label =\"test\")  \n",
    "     \n",
    "\n",
    "    plt.xlabel(\"complexity\")\n",
    "    plt.ylabel(\"MSE\")\n",
    "    plt.title(\"Plot of the MSE as a function of complexity of the model\")\n",
    "    plt.legend()\n",
    "    plt.grid()     \n",
    "    #plt.savefig('Task2plot(n='+str(n)+').pdf')\n",
    "    plt.show() \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The MIT License (MIT)\n",
    "#\n",
    "# Copyright © 2021 Fridtjof Gjengset, Adele Zaini, Gaute Holen\n",
    "#\n",
    "# Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated\n",
    "# documentation files (the “Software”), to deal in the Software without restriction, including without limitation the\n",
    "# rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software,\n",
    "# and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n",
    "#\n",
    "# The above copyright notice and this permission notice shall be included in all copies or substantial portions of\n",
    "# the Software. THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT\n",
    "# LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT\n",
    "# SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF\n",
    "# CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS\n",
    "# IN THE SOFTWARE.\n",
    "\n",
    "import numpy as np\n",
    "from random import random, seed\n",
    "import pandas as pd\n",
    "#from linear_regression import FrankeFunction, create_X, Split_and_Scale, OLS_solver, MSE, R2\n",
    "\n",
    "degree=5\n",
    "\n",
    "# Create vanilla dataset:\n",
    "np.random.seed(3155)\n",
    "\n",
    "n = 25\n",
    "\n",
    "x = np.linspace(0,1,n)\n",
    "y = np.linspace(0,1,n) \n",
    "x, y = np.meshgrid(x,y)\n",
    "\n",
    "sigma_N = 0.01; mu_N = 0 #change for value of sigma_N to appropriate values\n",
    "z = FrankeFunction(x,y) +mu_N+sigma_N*np.random.randn(n,n)#+ np.random.normal(mu_N,sigma_N,n**2)  #adding noise to the dataset\n",
    "\n",
    "Plot_FrankeFunction(x,y,z, title=\"Noisy dataset\")\n",
    "\n",
    "# OLS\n",
    "X = create_X(x, y, degree)\n",
    "X_train, X_test, z_train, z_test = Split_and_Scale(X,np.ravel(z)) #StardardScaler, test_size=0.2, scale=true\n",
    "ols_beta, z_tilde,z_predict = OLS_solver(X_train, X_test, z_train, z_test)\n",
    "\n",
    "# Error Analysis\n",
    "prec=4\n",
    "print(\"––––––––––––––––––––––––––––––––––––––––––––\")\n",
    "print(\"Train MSE:\", np.round(MSE(z_train,z_tilde),prec))\n",
    "print(\"Test MSE:\", np.round(MSE(z_test,z_predict),prec))\n",
    "print(\"––––––––––––––––––––––––––––––––––––––––––––\")\n",
    "print(\"Train R2:\", np.round(R2(z_train,z_tilde),prec))\n",
    "print(\"Test R2:\", np.round(R2(z_test,z_predict),prec))\n",
    "print(\"––––––––––––––––––––––––––––––––––––––––––––\")\n",
    "\n",
    "# Confidence interval\n",
    "beta_ols_variance = sigma_N**2 * np.linalg.pinv(X_train.T @ X_train) #Calculates variance of beta\n",
    "var_diag=np.diag(beta_ols_variance)\n",
    "ci1 = ols_beta - 1.96 * np.sqrt(var_diag)/(X.shape[0])\n",
    "ci2 = ols_beta + 1.96 * np.sqrt(var_diag)/(X.shape[0])\n",
    "print('Confidence interval of β-estimator at 95 %:')\n",
    "ci_df = {r'$β_{-}$': ci1,\n",
    "         r'$β_{ols}$': ols_beta,\n",
    "         r'$β_{+}$': ci2}\n",
    "ci_df = pd.DataFrame(ci_df)\n",
    "display(np.round(ci_df,3))#prec\n",
    "print(\"––––––––––––––––––––––––––––––––––––––––––––\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from random import random, seed\n",
    "#from linear_regression import FrankeFunction, create_X, Split_and_Scale, OLS_solver, MSE, R2, plot_ols_compelxity\n",
    "\n",
    "\n",
    "# Create vanilla dataset:\n",
    "np.random.seed(1234)\n",
    "\n",
    "n = 25\n",
    "\n",
    "x = np.linspace(0,1,n)\n",
    "y = np.linspace(0,1,n) \n",
    "\n",
    "x,y = np.meshgrid(x,y)\n",
    "sigma_N = 0.1; mu_N = 0 #change for value of sigma_N to appropriate values\n",
    "z = FrankeFunction(x,y) +mu_N +sigma_N*np.random.randn(n,n)\t#adding noise to the dataset\n",
    "\n",
    "complexity=range(2,20)\n",
    "\n",
    "plot_ols_complexity(x,y,z, complexity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The MIT License (MIT)\n",
    "#\n",
    "# Copyright © 2021 Fridtjof Gjengset, Adele Zaini, Gaute Holen\n",
    "#\n",
    "# Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated\n",
    "# documentation files (the “Software”), to deal in the Software without restriction, including without limitation the\n",
    "# rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software,\n",
    "# and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n",
    "#\n",
    "# The above copyright notice and this permission notice shall be included in all copies or substantial portions of\n",
    "# the Software. THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT\n",
    "# LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT\n",
    "# SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF\n",
    "# CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS\n",
    "# IN THE SOFTWARE.\n",
    "\n",
    "import numpy as np\n",
    "from random import random, seed\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator, FormatStrFormatter\n",
    "\n",
    "\n",
    "# FrankeFunction: a two-variables function to create the dataset of our vanilla problem\n",
    "def FrankeFunction(x,y): #code from task\n",
    "\tterm1 = 0.75*np.exp(-(0.25*(9*x-2)**2) - 0.25*((9*y-2)**2))\n",
    "\tterm2 = 0.75*np.exp(-((9*x+1)**2)/49.0 - 0.1*(9*y+1))\n",
    "\tterm3 = 0.5*np.exp(-(9*x-7)**2/4.0 - 0.25*((9*y-3)**2))\n",
    "\tterm4 = -0.2*np.exp(-(9*x-4)**2 - (9*y-7)**2)\n",
    "\treturn term1 + term2 + term3 + term4\n",
    " \n",
    "# 3D plot of FrankeFunction\n",
    "def Plot_FrankeFunction(x,y,z, title=\"Dataset\"): #code from task\n",
    "    fig = plt.figure()\n",
    "    ax = fig.gca(projection=\"3d\")\n",
    "\n",
    "    # Plot the surface.\n",
    "    surf = ax.plot_surface(x, y, z, cmap=cm.coolwarm, linewidth=0, antialiased=False)\n",
    "\n",
    "    # Customize the z axis.\n",
    "    ax.set_zlim(-0.10, 1.40)\n",
    "    ax.zaxis.set_major_locator(LinearLocator(10))\n",
    "    ax.zaxis.set_major_formatter(FormatStrFormatter('%.02f'))\n",
    "\n",
    "    # Add a color bar which maps values to colors.\n",
    "    fig.colorbar(surf, shrink=0.5, aspect=5)\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "# Error analysis: MSE and R2 score\n",
    "def R2(y_data, y_model): #week 35 exercise\n",
    "    return 1 - np.sum((y_data - y_model) ** 2) / np.sum((y_data - np.mean(y_data)) ** 2)\n",
    "def MSE(y_data,y_model):\n",
    "    n = np.size(y_model)\n",
    "    return np.sum((y_data-y_model)**2)/n\n",
    "\n",
    "# SVD theorem\n",
    "def SVD(A): #week35 SVD change to week 36\n",
    "    U, S, VT = np.linalg.svd(A,full_matrices=True)\n",
    "    D = np.zeros((len(U),len(VT)))\n",
    "    print(\"shape D= \", np.shape(D))\n",
    "    print(\"Shape S= \",np.shape(S))\n",
    "    print(\"lenVT =\",len(VT))\n",
    "    print(\"lenU =\",len(U))\n",
    "    D = np.eye(len(U),len(VT))*S\n",
    "    \"\"\"\n",
    "    for i in range(0,VT.shape[0]): #was len(VT)\n",
    "        D[i,i]=S[i]\n",
    "        print(\"i=\",i)\"\"\"\n",
    "    return U @ D @ VT\n",
    "\n",
    "# Design matrix\n",
    "def create_X(x, y, n): # week 35-36 lecture slides\n",
    "\tif len(x.shape) > 1:\n",
    "\t\tx = np.ravel(x)\n",
    "\t\ty = np.ravel(y)\n",
    "\n",
    "\tN = len(x)\n",
    "\tl = int((n+1)*(n+2)/2)\t\t# Number of elements in beta, number of feutures (order-degree of polynomial)\n",
    "\tX = np.ones((N,l))\n",
    "\n",
    "\tfor i in range(1,n+1):\n",
    "\t\tq = int((i)*(i+1)/2)\n",
    "\t\tfor k in range(i+1):\n",
    "\t\t\tX[:,q+k] = (x**(i-k))*(y**k)\n",
    "\n",
    "\treturn X\n",
    "  \n",
    "# Splitting and rescaling data (rescaling is optional)\n",
    "# Default values: 20% of test data and the scaler is StandardScaler without std.dev.\n",
    "def Split_and_Scale(X,z,test_size=0.2, scale=True):\n",
    "\n",
    "    #Splitting training and test data\n",
    "    X_train, X_test, z_train, z_test = train_test_split(X, z, test_size=test_size)\n",
    "\n",
    "    # Rescaling X and z (optional)\n",
    "    if scale==True:\n",
    "        scaler_X = StandardScaler(with_std=False)\n",
    "        scaler_X.fit(X_train)\n",
    "        X_train = scaler_X.transform(X_train)\n",
    "        X_test = scaler_X.transform(X_test)\n",
    "\n",
    "        scaler_z = StandardScaler(with_std=False)\n",
    "        z_train = np.squeeze(scaler_z.fit_transform(z_train.reshape(-1, 1)))\n",
    "        z_test = np.squeeze(scaler_z.transform(z_test.reshape(-1, 1)))\n",
    "      \n",
    "    return X_train, X_test, z_train, z_test\n",
    "\n",
    "# OLS equation\n",
    "def OLS_solver(X_train, X_test, z_train, z_test):\n",
    "\n",
    "\t# Calculating Beta Ordinary Least Square with matrix inversion\n",
    "\tols_beta = np.linalg.pinv(X_train.T @ X_train) @ X_train.T @ z_train #psudoinverse\n",
    "  \n",
    "\tz_tilde = X_train @ ols_beta\n",
    "\tz_predict = X_test @ ols_beta\n",
    "\n",
    "\treturn ols_beta, z_tilde, z_predict\n",
    " \n",
    "def Confidence_Interval(beta, X, sigma=1):\n",
    "    #Calculates variance of beta, extracting just the diagonal elements of the matrix\n",
    "    #var(B_j)=sigma^2*(X^T*X)^{-1}_{jj}\n",
    "    beta_variance = np.diag(sigma**2 * np.linalg.pinv(X.T @ X))\n",
    "    ci1 = beta - 1.96 * np.sqrt(beta_variance)/(X.shape[0])\n",
    "    ci2 = beta + 1.96 * np.sqrt(beta_variance)/(X.shape[0])\n",
    "    print('Confidence interval of β-estimator at 95 %:')\n",
    "    ci_df = {r'$β_{-}$': ci1,\n",
    "             r'$β_{ols}$': beta,\n",
    "             r'$β_{+}$': ci2}\n",
    "    ci_df = pd.DataFrame(ci_df)\n",
    "    display(np.round(ci_df,3))\n",
    "    return ci1, ci2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The MIT License (MIT)\n",
    "#\n",
    "# Copyright © 2021 Fridtjof Gjengset, Adele Zaini, Gaute Holen\n",
    "#\n",
    "# Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated\n",
    "# documentation files (the “Software”), to deal in the Software without restriction, including without limitation the\n",
    "# rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software,\n",
    "# and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n",
    "#\n",
    "# The above copyright notice and this permission notice shall be included in all copies or substantial portions of\n",
    "# the Software. THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT\n",
    "# LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT\n",
    "# SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF\n",
    "# CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS\n",
    "# IN THE SOFTWARE.\n",
    "\n",
    "import numpy as np\n",
    "from random import random, seed\n",
    "import pandas as pd\n",
    "#from linear_regression import FrankeFunction, create_X, Split_and_Scale, OLS_solver, MSE, R2, Plot_FrankeFunction\n",
    "\n",
    "degree=5\n",
    "\n",
    "# Create vanilla dataset:\n",
    "np.random.seed(3155)\n",
    "\n",
    "n = 25\n",
    "\n",
    "x = np.linspace(0,1,n)\n",
    "y = np.linspace(0,1,n) \n",
    "x, y = np.meshgrid(x,y)\n",
    "\n",
    "sigma_N = 0.1; mu_N = 0 #change for value of sigma_N to appropriate values\n",
    "z = FrankeFunction(x,y) +mu_N+sigma_N*np.random.randn(n,n)#+ np.random.normal(mu_N,sigma_N,n**2)  #adding noise to the dataset\n",
    "\n",
    "Plot_FrankeFunction(x,y,z, title=\"Original noisy dataset\")\n",
    "\n",
    "# OLS\n",
    "X = create_X(x, y, degree)\n",
    "X_train, X_test, z_train, z_test = Split_and_Scale(X,np.ravel(z)) #StardardScaler, test_size=0.2, scale=true\n",
    "ols_beta, z_tilde,z_predict = OLS_solver(X_train, X_test, z_train, z_test)\n",
    "\n",
    "# Error Analysis\n",
    "prec=4\n",
    "print(\"––––––––––––––––––––––––––––––––––––––––––––\")\n",
    "print(\"Train MSE:\", np.round(MSE(z_train,z_tilde),prec))\n",
    "print(\"Test MSE:\", np.round(MSE(z_test,z_predict),prec))\n",
    "print(\"––––––––––––––––––––––––––––––––––––––––––––\")\n",
    "print(\"Train R2:\", np.round(R2(z_train,z_tilde),prec))\n",
    "print(\"Test R2:\", np.round(R2(z_test,z_predict),prec))\n",
    "print(\"––––––––––––––––––––––––––––––––––––––––––––\")\n",
    "\n",
    "# Confidence interval\n",
    "#c1, c2 = Confidence_Interval(ols_beta, X_train, sigma_N)\n",
    "print(\"––––––––––––––––––––––––––––––––––––––––––––\")\n",
    "\n",
    "beta_ols_variance = sigma_N**2 * np.linalg.pinv(X_train.T @ X_train) #Calculates variance of beta\n",
    "var_diag=np.diag(beta_ols_variance)\n",
    "ci1 = ols_beta - 1.96 * np.sqrt(var_diag)/(X.shape[0])\n",
    "ci2 = ols_beta + 1.96 * np.sqrt(var_diag)/(X.shape[0])\n",
    "print('Confidence interval of β-estimator at 95 %:')\n",
    "ci_df = {r'$β_{-}$': ci1,\n",
    "         r'$β_{ols}$': ols_beta,\n",
    "         r'$β_{+}$': ci2}\n",
    "ci_df = pd.DataFrame(ci_df)\n",
    "display(np.round(ci_df,3))#prec\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The MIT License (MIT)\n",
    "#\n",
    "# Copyright © 2021 Fridtjof Gjengset, Adele Zaini, Gaute Holen\n",
    "#\n",
    "# Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated\n",
    "# documentation files (the “Software”), to deal in the Software without restriction, including without limitation the\n",
    "# rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software,\n",
    "# and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n",
    "#\n",
    "# The above copyright notice and this permission notice shall be included in all copies or substantial portions of\n",
    "# the Software. THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT\n",
    "# LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT\n",
    "# SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF\n",
    "# CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS\n",
    "# IN THE SOFTWARE.\n",
    "\n",
    "import numpy as np\n",
    "from random import random, seed\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator, FormatStrFormatter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import resample\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "\n",
    "# FrankeFunction: a two-variables function to create the dataset of our vanilla problem\n",
    "def FrankeFunction(x,y):\n",
    "\tterm1 = 0.75*np.exp(-(0.25*(9*x-2)**2) - 0.25*((9*y-2)**2))\n",
    "\tterm2 = 0.75*np.exp(-((9*x+1)**2)/49.0 - 0.1*(9*y+1))\n",
    "\tterm3 = 0.5*np.exp(-(9*x-7)**2/4.0 - 0.25*((9*y-3)**2))\n",
    "\tterm4 = -0.2*np.exp(-(9*x-4)**2 - (9*y-7)**2)\n",
    "\treturn term1 + term2 + term3 + term4\n",
    " \n",
    "# 3D plot of FrankeFunction\n",
    "def Plot_FrankeFunction(x,y,z, title=\"Dataset\"):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.gca(projection=\"3d\")\n",
    "\n",
    "    # Plot the surface.\n",
    "    surf = ax.plot_surface(x, y, z, cmap=cm.coolwarm, linewidth=0, antialiased=False)\n",
    "\n",
    "    # Customize the z axis.\n",
    "    ax.set_zlim(-0.10, 1.40)\n",
    "    ax.zaxis.set_major_locator(LinearLocator(10))\n",
    "    ax.zaxis.set_major_formatter(FormatStrFormatter('%.02f'))\n",
    "\n",
    "    # Add a color bar which maps values to colors.\n",
    "    fig.colorbar(surf, shrink=0.5, aspect=5)\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "    \n",
    "# Create xyz dataset from the FrankeFunction with a added normal distributed noise\n",
    "def create_xyz_dataset(n,mu_N, sigma_N):\n",
    "    x = np.linspace(0,1,n)\n",
    "    y = np.linspace(0,1,n)\n",
    "\n",
    "    x,y = np.meshgrid(x,y)\n",
    "    z = FrankeFunction(x,y) +mu_N +sigma_N*np.random.randn(n,n)\n",
    "    \n",
    "    return x,y,z\n",
    "\n",
    "# Error analysis: MSE and R2 score\n",
    "def R2(y_data, y_model): #week 35 exercise\n",
    "    return 1 - np.sum((y_data - y_model) ** 2) / np.sum((y_data - np.mean(y_data)) ** 2)\n",
    "def MSE(y_data,y_model):\n",
    "    n = np.size(y_model)\n",
    "    return np.sum((y_data-y_model)**2)/n\n",
    "\n",
    "# SVD theorem\n",
    "def SVD(A):\n",
    "    U, S, VT = np.linalg.svd(A,full_matrices=True)\n",
    "    D = np.zeros((len(U),len(VT)))\n",
    "    print(\"shape D= \", np.shape(D))\n",
    "    print(\"Shape S= \",np.shape(S))\n",
    "    print(\"lenVT =\",len(VT))\n",
    "    print(\"lenU =\",len(U))\n",
    "    D = np.eye(len(U),len(VT))*S\n",
    "    \"\"\"\n",
    "    for i in range(0,VT.shape[0]): #was len(VT)\n",
    "        D[i,i]=S[i]\n",
    "        print(\"i=\",i)\"\"\"\n",
    "    return U @ D @ VT\n",
    "    \n",
    "# SVD inversion\n",
    "def SVDinv(A):\n",
    "    U, s, VT = np.linalg.svd(A)\n",
    "    # reciprocals of singular values of s\n",
    "    d = 1.0 / s\n",
    "    # create m x n D matrix\n",
    "    D = np.zeros(A.shape)\n",
    "    # populate D with n x n diagonal matrix\n",
    "    D[:A.shape[1], :A.shape[1]] = np.diag(d)\n",
    "    UT = np.transpose(U)\n",
    "    V = np.transpose(VT)\n",
    "    return np.matmul(V,np.matmul(D.T,UT))\n",
    "\n",
    "# Design matrix for two indipendent variables x,y\n",
    "def create_X(x, y, n):\n",
    "\tif len(x.shape) > 1:\n",
    "\t\tx = np.ravel(x)\n",
    "\t\ty = np.ravel(y)\n",
    "\n",
    "\tN = len(x)\n",
    "\tl = int((n+1)*(n+2)/2)\t\t# Number of elements in beta, number of feutures (degree of polynomial)\n",
    "\tX = np.ones((N,l))\n",
    "\n",
    "\tfor i in range(1,n+1):\n",
    "\t\tq = int((i)*(i+1)/2)\n",
    "\t\tfor k in range(i+1):\n",
    "\t\t\tX[:,q+k] = (x**(i-k))*(y**k)\n",
    "\n",
    "\treturn X\n",
    "  \n",
    "# Splitting and rescaling data (rescaling is optional)\n",
    "# Default values: 20% of test data and the scaler is StandardScaler without std.dev.\n",
    "def Split_and_Scale(X,z,test_size=0.2, scale=True):\n",
    "\n",
    "    #Splitting training and test data\n",
    "    X_train, X_test, z_train, z_test = train_test_split(X, z, test_size=test_size)\n",
    "\n",
    "    # Rescaling X and z (optional)\n",
    "    if scale==True:\n",
    "        scaler_X = StandardScaler(with_std=False)\n",
    "        scaler_X.fit(X_train)\n",
    "        X_train = scaler_X.transform(X_train)\n",
    "        X_test = scaler_X.transform(X_test)\n",
    "\n",
    "        scaler_z = StandardScaler(with_std=False)\n",
    "        z_train = np.squeeze(scaler_z.fit_transform(z_train.reshape(-1, 1))) #scaler_z.fit_transform(z_train) #\n",
    "        z_test = np.squeeze(scaler_z.transform(z_test.reshape(-1, 1))) #scaler_z.transform(z_test) #\n",
    "      \n",
    "    return X_train, X_test, z_train, z_test\n",
    "\n",
    "# OLS equation\n",
    "def OLS_solver(X_train, X_test, z_train, z_test):\n",
    "\n",
    "\t# Calculating Beta Ordinary Least Square Equation with matrix pseudoinverse\n",
    "    # Altervatively to Numpy pseudoinverse it is possible to use the SVD theorem to evalute the inverse of a matrix (even in case it is singular). Just replace 'np.linalg.pinv' with 'SVDinv'.\n",
    "\tols_beta = np.linalg.pinv(X_train.T @ X_train) @ X_train.T @ z_train\n",
    "  \n",
    "\tz_tilde = X_train @ ols_beta # z_prediction of the train data\n",
    "\tz_predict = X_test @ ols_beta # z_prediction of the test data\n",
    "  \n",
    "\treturn ols_beta, z_tilde, z_predict\n",
    "\n",
    "# Plot MSE in function of complexity of the model\n",
    "def plot_ols_complexity(x, y, z, complexity = np.arange(2,21), title=\"MSE as a function of model complexity\"):\n",
    "\n",
    "    MSE_train_set = []\n",
    "    MSE_test_set = []\n",
    "\n",
    "    for degree in complexity:\n",
    "\n",
    "        X = create_X(x, y, degree)\n",
    "        X_train, X_test, z_train, z_test = Split_and_Scale(X,z) #StardardScaler, test_size=0.2, scale=true\n",
    "        ols_beta, z_tilde, z_predict = OLS_solver(X_train, X_test, z_train, z_test)\n",
    "\n",
    "        MSE_train_set.append(MSE(z_train,z_tilde))\n",
    "        MSE_test_set.append(MSE(z_test,z_predict))\n",
    "\n",
    "    plt.plot(complexity,MSE_train_set, label =r\"$MSE_{train}$\")\n",
    "    plt.plot(complexity,MSE_test_set, label =r\"$MSE_{test}$\")  \n",
    "     \n",
    "    plt.xlabel(\"complexity\")\n",
    "    plt.ylabel(\"MSE\")\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.grid()     \n",
    "    #plt.savefig('Task2plot(n='+str(n)+').pdf')\n",
    "    plt.show()\n",
    "    \n",
    "# Bootstrap resampling\n",
    "# Return a (m x n_bootstraps) matrix with the column vectors z_pred for each bootstrap iteration.\n",
    "def bootstrap(X_train, X_test, z_train, z_test, n_boostraps=100, model=LinearRegression()):\n",
    "    \"\"\"\n",
    "    z_pred = np.empty((z_test.shape[0], n_boostraps))\n",
    "    for i in range(n_boostraps):\n",
    "        X_, z_ = resample(X_train, z_train)\n",
    "        z_pred[:, i] = model.fit(X_, z_).predict(X_test).ravel()\n",
    "    \"\"\"\n",
    "    z_pred_boot = np.empty((z_test.shape[0], n_boostraps))\n",
    "    for i in range(n_boostraps):\n",
    "        # Draw a sample of our dataset\n",
    "        X_sample, z_sample = resample(X_train, z_train)\n",
    "        # Perform OLS equation\n",
    "        beta, z_tilde, z_pred = OLS_solver(X_train, X_test, z_train, z_test)\n",
    "        # Evaluate the new model on the same test data each time.\n",
    "        z_pred_boot[:, i] = z_pred.ravel()\n",
    "\n",
    "    return z_pred_boot\n",
    "    \n",
    "# Bias-variance tradeoff\n",
    "\n",
    "# Note: Expectations and variances taken w.r.t. different training\n",
    "# data sets, hence the axis=1. Subsequent means are taken across the test data\n",
    "# set in order to obtain a total value, but before this we have error/bias/variance\n",
    "# calculated per data point in the test set.\n",
    "# Note 2: The use of keepdims=True is important in the calculation of bias as this\n",
    "# maintains the column vector form. Dropping this yields very unexpected results.\n",
    "\n",
    "# conclude with cross validation\n",
    "\n",
    "def bias_variance_analysis(X_train, X_test, z_train, z_test, resampling=\"bootstrap\", n_resampling = 100, model=LinearRegression()):\n",
    "    if(resampling==\"bootstrap\"):\n",
    "        z_pred = bootstrap(X_train, X_test, z_train, z_test, n_boostraps = n_resampling, model=model)\n",
    "    \"\"\" else:\n",
    "        z_pred = crossvalidation(X_train, X_test, z_train, z_test, n_resampling)\n",
    "    \"\"\"\n",
    "    #z_test.reshape(n*n,1)\n",
    "    error = np.mean( np.mean((z_test.reshape(-1,1) - z_pred)**2, axis=1, keepdims=True) ) # MSE\n",
    "    bias2 = np.mean( (z_test.reshape(-1,1) - np.mean(z_pred, axis=1, keepdims=True))**2 ) # bias^2\n",
    "    variance = np.mean( np.var(z_pred, axis=1, keepdims=True) )\n",
    "\n",
    "    return error, bias2, variance\n",
    "    \n",
    "# Plot bias-variance tradeoff in function of complexity of the model\n",
    "def bias_variance_complexity(x, y, z, complexity = np.arange(1,15), n_resampling = 100, test_size = 0.2, plot=True, title=\"Bias-variance analysis: MSE as a function of model complexity\"):\n",
    "\n",
    "    error = np.zeros(complexity.size)\n",
    "    bias = np.zeros(complexity.size)\n",
    "    variance = np.zeros(complexity.size)\n",
    "\n",
    "    for degree in complexity:\n",
    "\n",
    "        X = create_X(x, y, degree)\n",
    "        X_train, X_test, z_train, z_test = Split_and_Scale(X,z,test_size=test_size) #StardardScaler, test_size=0.2, scale=true\n",
    "        model = make_pipeline(PolynomialFeatures(degree=degree), LinearRegression(fit_intercept=False))\n",
    "        error[degree], bias[degree], variance[degree] = bias_variance_analysis(X_train, X_test, z_train, z_test, n_resampling = n_resampling, model=model)\n",
    "    \n",
    "        # For debugging\n",
    "        print('Error:', error[degree])\n",
    "        print('Bias^2:', bias[degree])\n",
    "        print('Var:', variance[degree])\n",
    "        print('{} >= {} + {} = {}'.format(error[degree], bias[degree], variance[degree], bias[degree]+variance[degree]))\n",
    "\n",
    "        # test: close to the precision...\n",
    "        \n",
    "    if (plot==True):\n",
    "        plt.plot(complexity, error, label='Error')\n",
    "        plt.plot(complexity, bias, label=r'$Bias^2$')\n",
    "        plt.plot(complexity, variance, label='Variance')\n",
    "        plt.xlabel(\"complexity\")\n",
    "        plt.ylabel(\"MSE\")\n",
    "        plt.title(title)\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    \n",
    "    return error, bias, variance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The MIT License (MIT)\n",
    "#\n",
    "# Copyright © 2021 Fridtjof Gjengset, Adele Zaini, Gaute Holen\n",
    "#\n",
    "# Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated\n",
    "# documentation files (the “Software”), to deal in the Software without restriction, including without limitation the\n",
    "# rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software,\n",
    "# and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n",
    "#\n",
    "# The above copyright notice and this permission notice shall be included in all copies or substantial portions of\n",
    "# the Software. THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT\n",
    "# LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT\n",
    "# SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF\n",
    "# CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS\n",
    "# IN THE SOFTWARE.\n",
    "\n",
    "import numpy as np\n",
    "from random import random, seed\n",
    "#from linear_regression import plot_ols_complexity, create_xyz_dataset, bias_variance_complexity, Plot_FrankeFunction\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def train_n(n,test_size):\n",
    "    return int(n*n*(1-test_size))\n",
    "    \n",
    "def test_n(n,test_size):\n",
    "    return int(n*n*test_size)\n",
    "    \n",
    "# Create vanilla dataset:\n",
    "np.random.seed(2018)\n",
    "\n",
    "# Datapoints (squared root of datapoints -> meshgrid)\n",
    "n = 25\n",
    "# Paramaters of noise distribution\n",
    "mu_N = 0; sigma_N = 0.2\n",
    "# Parameter of splitting data\n",
    "test_size = 0.2\n",
    "\n",
    "x,y,z = create_xyz_dataset(n,mu_N, sigma_N); z = z.ravel() #z.reshape(-1,1)\n",
    "print(x.shape)\n",
    "\n",
    "print(\"Part 1: $MSE_{train}$ and $MSE_{test}$ in function of the complexity of the model (degree-order of polynomial) \\n\")\n",
    "complexity = np.arange(2,21)\n",
    "plot_ols_complexity(x,y,z, complexity)\n",
    "\n",
    "print(\"Part 2: perform a bias-variance tradeoff analysis \\n\")\n",
    "complexity = np.arange(0,11)\n",
    "print(\"Train datapoints:\", train_n(n,test_size))\n",
    "print(\"Test datapoints:\", test_n(n,test_size))\n",
    "bias_variance_complexity(x, y, z, complexity, test_size=test_size)\n",
    "\n",
    "print(\"Bias-variance tradeoff analysis with variation in training and testing datapoints\")\n",
    "n_ = [25,40]\n",
    "test_size_ = [0.2, 0.33]\n",
    "complexity = np.arange(0,18)\n",
    "\n",
    "fig=plt.figure(figsize=(15, 10))\n",
    "\n",
    "for i in n_:\n",
    "\n",
    "    x,y,z = create_xyz_dataset(i,mu_N, sigma_N); z = z.reshape(i*i,1)\n",
    "    \n",
    "    for ts in test_size_:\n",
    "        print(\"Datapoints:\", i*i, \"– Test size:\", round(ts,3))\n",
    "        \n",
    "        error, bias, variance = bias_variance_complexity(x, y, z, complexity, test_size=ts, plot=False)\n",
    "        plt.plot(complexity, error, label='Error-n_train'+str(train_n(i,ts))+'-n_test'+str(test_n(i,ts)))\n",
    "        plt.plot(complexity, bias, label=r'$Bias^2$-n_train'+str(train_n(i,ts))+'-n_test'+str(test_n(i,ts)))\n",
    "        plt.plot(complexity, variance, label='Variance-n_train'+str(train_n(i,ts))+'-n_test'+str(test_n(i,ts)))\n",
    "        \n",
    "plt.xlabel(\"complexity\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.title(\"Bias variance analysis - datapoints variantions\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    " \n",
    "\"\"\"\n",
    "n = 40\n",
    "complexity = np.arange(0,11)\n",
    "print(\"Train datapoints:\", train_n(n,test_size))\n",
    "print(\"Test datapoints:\", test_n(n,test_size))\n",
    "print(\"Complexity:\", complexity)\n",
    "x,y,z = create_xyz_dataset(n,mu_N, sigma_N); z = z.reshape(n*n,1)\n",
    "plot_bias_variance_complexity(x, y, z, complexity, test_size=test_size)\n",
    "\n",
    "complexity = np.arange(0,18)\n",
    "print(\"Train datapoints:\", train_n(n,test_size))\n",
    "print(\"Test datapoints:\", test_n(n,test_size))\n",
    "print(\"Complexity:\", complexity)\n",
    "plot_bias_variance_complexity(x, y, z, complexity, test_size=test_size)\n",
    "\n",
    "n = 40\n",
    "complexity = np.arange(0,18)\n",
    "test_size=0.3\n",
    "print(\"Train datapoints:\", train_n(n,test_size))\n",
    "print(\"Test datapoints:\", test_n(n,test_size))\n",
    "print(\"Complexity:\", complexity)\n",
    "plot_bias_variance_complexity(x, y, z, complexity, test_size=test_size)\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 10)\n",
      "Part 1: $MSE_{train}$ and $MSE_{test}$ in function of the complexity of the model (degree-order of polynomial) \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 2: perform a bias-variance tradeoff analysis \n",
      "\n",
      "Polynomial degree: 0\n",
      "Error: 0.11226606850056169\n",
      "Bias^2: 0.11226606850056169\n",
      "Var: 3.0814879110195774e-33\n",
      "0.11226606850056169 >= 0.11226606850056169 + 3.0814879110195774e-33 = 0.11226606850056169\n",
      "Polynomial degree: 1\n",
      "Error: 0.05136365468965304\n",
      "Bias^2: 0.051363654689653\n",
      "Var: 2.072541361403714e-32\n",
      "0.05136365468965304 >= 0.051363654689653 + 2.072541361403714e-32 = 0.051363654689653\n",
      "Polynomial degree: 2\n",
      "Error: 0.0529004730555096\n",
      "Bias^2: 0.052900473055509586\n",
      "Var: 1.3144471870442885e-32\n",
      "0.0529004730555096 >= 0.052900473055509586 + 1.3144471870442885e-32 = 0.052900473055509586\n",
      "Polynomial degree: 3\n",
      "Error: 0.06724842110644491\n",
      "Bias^2: 0.06724842110644491\n",
      "Var: 1.8460038516951655e-32\n",
      "0.06724842110644491 >= 0.06724842110644491 + 1.8460038516951655e-32 = 0.06724842110644491\n",
      "Polynomial degree: 4\n",
      "Error: 0.044394044105969865\n",
      "Bias^2: 0.044394044105969865\n",
      "Var: 5.7007526353862184e-33\n",
      "0.044394044105969865 >= 0.044394044105969865 + 5.7007526353862184e-33 = 0.044394044105969865\n",
      "Polynomial degree: 5\n",
      "Error: 0.03923744631441321\n",
      "Bias^2: 0.03923744631441321\n",
      "Var: 6.904458850628241e-33\n",
      "0.03923744631441321 >= 0.03923744631441321 + 6.904458850628241e-33 = 0.03923744631441321\n",
      "Polynomial degree: 6\n",
      "Error: 0.08984063118516582\n",
      "Bias^2: 0.08984063118516583\n",
      "Var: 6.933347799794049e-33\n",
      "0.08984063118516582 >= 0.08984063118516583 + 6.933347799794049e-33 = 0.08984063118516583\n",
      "Polynomial degree: 7\n",
      "Error: 0.06080879578839323\n",
      "Bias^2: 0.060808795788393245\n",
      "Var: 3.0814879110195774e-33\n",
      "0.06080879578839323 >= 0.060808795788393245 + 3.0814879110195774e-33 = 0.060808795788393245\n",
      "Polynomial degree: 8\n",
      "Error: 0.7622578380405167\n",
      "Bias^2: 0.7622578380405167\n",
      "Var: 2.465190328815662e-33\n",
      "0.7622578380405167 >= 0.7622578380405167 + 2.465190328815662e-33 = 0.7622578380405167\n",
      "Polynomial degree: 9\n",
      "Error: 0.8337569394263472\n",
      "Bias^2: 0.8337569394263472\n",
      "Var: 5.5466782398352394e-33\n",
      "0.8337569394263472 >= 0.8337569394263472 + 5.5466782398352394e-33 = 0.8337569394263472\n",
      "Polynomial degree: 10\n",
      "Error: 2.6951937703586024\n",
      "Bias^2: 2.6951937703586024\n",
      "Var: 5.5466782398352394e-33\n",
      "2.6951937703586024 >= 2.6951937703586024 + 5.5466782398352394e-33 = 2.6951937703586024\n",
      "Polynomial degree: 11\n",
      "Error: 4.528372092850377\n",
      "Bias^2: 4.528372092850377\n",
      "Var: 0.0\n",
      "4.528372092850377 >= 4.528372092850377 + 0.0 = 4.528372092850377\n",
      "Polynomial degree: 12\n",
      "Error: 9.486087593085013\n",
      "Bias^2: 9.486087593085013\n",
      "Var: 3.266377185680752e-32\n",
      "9.486087593085013 >= 9.486087593085013 + 3.266377185680752e-32 = 9.486087593085013\n",
      "Polynomial degree: 13\n",
      "Error: 4.695216509593522\n",
      "Bias^2: 4.695216509593522\n",
      "Var: 3.851859888774472e-35\n",
      "4.695216509593522 >= 4.695216509593522 + 3.851859888774472e-35 = 4.695216509593522\n",
      "Polynomial degree: 14\n",
      "Error: 11.05107498328932\n",
      "Bias^2: 11.051074983289322\n",
      "Var: 5.5466782398352394e-33\n",
      "11.05107498328932 >= 11.051074983289322 + 5.5466782398352394e-33 = 11.051074983289322\n",
      "Polynomial degree: 15\n",
      "Error: 1.9187389425496406\n",
      "Bias^2: 1.9187389425496408\n",
      "Var: 0.0\n",
      "1.9187389425496406 >= 1.9187389425496408 + 0.0 = 1.9187389425496408\n",
      "Polynomial degree: 16\n",
      "Error: 27.649270343480378\n",
      "Bias^2: 27.649270343480374\n",
      "Var: 1.232595164407831e-33\n",
      "27.649270343480378 >= 27.649270343480374 + 1.232595164407831e-33 = 27.649270343480374\n",
      "Polynomial degree: 17\n",
      "Error: 712.733075487406\n",
      "Bias^2: 712.7330754874063\n",
      "Var: 1.0099884777157766e-29\n",
      "712.733075487406 >= 712.7330754874063 + 1.0099884777157766e-29 = 712.7330754874063\n",
      "Polynomial degree: 18\n",
      "Error: 3.7102201799048187\n",
      "Bias^2: 3.7102201799048182\n",
      "Var: 2.6131017485446015e-31\n",
      "3.7102201799048187 >= 3.7102201799048182 + 2.6131017485446015e-31 = 3.7102201799048182\n",
      "Polynomial degree: 19\n",
      "Error: 353.4595003462042\n",
      "Bias^2: 353.4595003462044\n",
      "Var: 0.0\n",
      "353.4595003462042 >= 353.4595003462044 + 0.0 = 353.4595003462044\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from random import random, seed\n",
    "#from linear_regression import plot_ols_complexity, create_xyz_dataset, bias_variance_complexity, Plot_FrankeFunction\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create vanilla dataset:\n",
    "np.random.seed(2018)\n",
    "\n",
    "# Datapoints (squared root of datapoints -> meshgrid)\n",
    "n = 10\n",
    "# Paramaters of noise distribution\n",
    "mu_N = 0; sigma_N = 0.2\n",
    "# Parameter of splitting data\n",
    "test_size = 0.2\n",
    "\n",
    "x,y,z = create_xyz_dataset(n,mu_N, sigma_N); z = z.ravel() #z.reshape(-1,1)\n",
    "print(x.shape)\n",
    "\n",
    "print(\"Part 1: $MSE_{train}$ and $MSE_{test}$ in function of the complexity of the model (degree-order of polynomial) \\n\")\n",
    "complexity = np.arange(2,21)\n",
    "plot_ols_complexity(x,y,z, complexity)\n",
    "\n",
    "print(\"Part 2: perform a bias-variance tradeoff analysis \\n\")\n",
    "complexity = np.arange(0,20)\n",
    "\n",
    "n_boostraps=100\n",
    "\n",
    "error = np.zeros(complexity.size)\n",
    "bias = np.zeros(complexity.size)\n",
    "variance = np.zeros(complexity.size)\n",
    "\n",
    "for degree in range(complexity.size):\n",
    "    X = create_X(x, y, degree)\n",
    "    X_train, X_test, z_train, z_test = train_test_split(X, z, test_size=0.2)\n",
    "    \n",
    "    z_pred_boot = np.empty((z_test.shape[0], n_boostraps))\n",
    "    \n",
    "    for i in range(n_boostraps):\n",
    "        # Draw a sample of our dataset\n",
    "        X_sample, z_sample = resample(X_train, z_train)\n",
    "        # Perform OLS equation\n",
    "        #model = make_pipeline(PolynomialFeatures(degree=degree), LinearRegression(fit_intercept=False))\n",
    "        beta, z_tilde, z_pred = OLS_solver(X_train, X_test, z_train, z_test)\n",
    "        # Evaluate the new model on the same test data each time.\n",
    "        z_pred_boot[:, i] = z_pred.ravel()\n",
    "        #z_pred_boot[:, i] = model.fit(X_sample, z_sample).predict(X_test).ravel()\n",
    "        \n",
    "        \n",
    "    error[degree] = np.mean( np.mean((z_test.reshape(-1,1) - z_pred_boot)**2, axis=1, keepdims=True) )\n",
    "    bias[degree] = np.mean( (z_test.reshape(-1,1) - np.mean(z_pred_boot, axis=1, keepdims=True))**2 )\n",
    "    variance[degree] = np.mean( np.var(z_pred_boot, axis=1, keepdims=True) )\n",
    "    \n",
    "    print('Polynomial degree:', degree)\n",
    "    print('Error:', error[degree])\n",
    "    print('Bias^2:', bias[degree])\n",
    "    print('Var:', variance[degree])\n",
    "    print('{} >= {} + {} = {}'.format(error[degree], bias[degree], variance[degree], bias[degree]+variance[degree]))\n",
    "\n",
    "plt.plot(complexity, error, label='Error')\n",
    "plt.plot(complexity, bias, label='bias')\n",
    "plt.plot(complexity, variance, label='Variance')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
